\documentclass[11pt,a4paper,openright,twoside]{book}
\def\myauthor{Adri√† Arrufat}
\def\mytitle{Adaptive transforms for intra video coding}
\usepackage[british]{babel}
\usepackage{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\usepackage[nottoc]{tocbibind} % see http://www.howtotex.com/packages/how-to-add-bibliography-and-more-to-table-of-contents/
\usepackage{titlesec,titletoc} % to modify titles and add partial tocs
\usepackage[printonlyused,withpage]{acronym} % options: printonlyused, withpage
\usepackage{imakeidx} % allows customizing the index in the makeindex command
\usepackage{emptypage} % removes headers and footers from empty pages
\usepackage[thickqspace,amssymb,noams]{SIunits} % consistent units support
\usepackage{subfig}
\usepackage{nicefrac}
\usepackage{contour} % for inexisting bold symbols
\usepackage{enumitem} % for custom labels
\contourlength{0.01em}

% lines and paragraphs
% \usepackage{setspace}
% \setstretch{1}
% \parskip=\smallskipamount
% \setlength{\parindent}{0pt}

% font configuration
\usepackage{amsmath, amssymb}
\usepackage[T1]{fontenc}
\usepackage{mathptmx}
\usepackage[scaled]{helvet}
% \usepackage{courier}

\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{pgfplots,tikz}
\usetikzlibrary{shapes,arrows,fit,calc,decorations.markings,intersections}
\usepgfplotslibrary{fillbetween}
\usepackage{bookmark} % needed for \bookmarksetup{startatroot}
\usepackage{hyperref}
\hypersetup{
	unicode=true,
	pdfencoding=auto,
	colorlinks=true,
	citecolor=blue,
	filecolor=red,
	linkcolor=Blue,
	urlcolor=blue,
	linktoc=all,
	pdfauthor={\myauthor},
	pdftitle={\mytitle},
	pdfsubject={video coding},
	pdfkeywords={video, image, transform},
	pdfinfo={
		CreationDate={D:20150121111947},
		%ModDate={...}
	},
}
% \urlstyle{same} % do not use monospaced fonts in urls

% Define a partial ToC to use at the beginning of every chapter
\providecommand{\chaptertoc}{
	\startcontents[chapters]
	\hrule
	\vspace{1em}
	\printcontents[chapters]{}{1}{{\bf\large Contents}}
	\hrule
}

% import mathematical and colour definitions
\input{./custom_defs.tex}

\numberwithin{equation}{section} % equations referred to sections
\numberwithin{figure}{section} % figures referred to sections
\numberwithin{table}{section} % tables referred to sections

\makeindex[options=-s index-alph-group.ist]

\title{\Huge\bf\mytitle}
\author{\myauthor}

\begin{document}
\frontmatter
\maketitle

\chapter*{Acknowledgements}
\label{cha:acknowledgements}
\addcontentsline{toc}{chapter}{Acknowledgements}

\setcounter{tocdepth}{5}
\tableofcontents
\addcontentsline{toc}{chapter}{Contents}
\cleardoublepage
\listoffigures
\cleardoublepage
\listoftables
\cleardoublepage

\mainmatter
\part{General introduction}
\label{prt:general_introduction}

\addcontentsline{toc}{section}{\protect\numberline{}Context}
\chapter*{Context}
\label{cha:context}

\part{State of the art}
\label{prt:state_of_the_art}

\chapter{Video coding fundamentals}
\label{cha:video_coding_fundamentals}
\chaptertoc

\section{Introduction to video coding}
\label{sec:introduction_to_video_coding}

\subsection{The need of video coding}
\label{sub:the_need_of_video_coding}

The purpose of video coding is to compress video files, which consist of
a sequence of images that, at some point, will be either transmitted or
stored.

For instance, a two-hour long film in \ac{HD} format ($1920 \times 1080$)
at a frame rate of 25 images per second and 8 bits to represent each one
of the \ac{RGB} channels, requires:
\[
	\frac{\unit{1920\times1080}{pix}}{\unit{1}{image}}
	\times \frac{\unit{25}{images}}{\unit{1}{s}}
	\times \unit{2}{\hour} \times \frac{\unit{3600}{s}}{\unit{1}{\hour}}
	\times \unit{3}{channels} \times \frac{\unit{8}{bits}}{\unit{1}{channel}}
	\approx \unit{1}{TB}
\]

Through this simple example, it is evident that video coding is
indispensable to store or stream video files.
Depending on the target quality, it is common to have compression rates
ranging from 100 to 1000.

For content providers, being able to reduce the size of the content they
broadcast implies increasing the number of contents they can store, as
well as the number of subscribers they can reach using the same
resources for storage and network capacity.

In 2013, two thirds of the \ac{IP} traffic was due to video
streaming, and this trend is only going to increase, reaching up to 84\%
of the \acs{IP} traffic by 2018~\cite{cisco-13-vni-forecast}.
Such statistics highlight the need of continuing the research on
new video coding techniques.

\section{The video coding system}
\label{sec:the_video_coding_system}

The video coding system describes a work flow to work with video
sequences.
It is composed of several stages, starting with the video acquisition at
the source and ending at the video display.
A good understanding of each part is crucial to be able to take the
proper decisions when delivering a video coding solution.

This section presents a scheme containing the most important concepts
used in state-of-the-art video coders.

Figure~\ref{fig:video_coding_system} describes how a complete video
coding system can be organised as a block diagram.

\begin{figure}[tb]
	\centering
	\input{./figures/video_coding_system.tex}
	\caption{Video coding system}
	\label{fig:video_coding_system}
\end{figure}

The composing blocks of the video system are explained more in detail in
the following subsections.

\subsection{Pre-processing}
\label{sub:pre_processing}

After the digital video has been acquired at the source, which may be of
many different sorts, such as natural scenes or synthetic
computer-generated content, it has to be processed in order to be
encoded.
Usually, the pre-processing stage can include some filtering, scaling
and colour space conversions on the raw video sequence.

\subsubsection{Colour space conversions}
\label{ssub:colour_space_conversions}
\index{HVS}
\index{YUV}
\index{gamma}
\index{luma}
\index{chroma}

Colour space conversions are used to change the colour
representation of the content to better fit the \ac{HVS}.
The raw video data is normally in \ac{RGB} format, corrected by the
transfer function of the camera ($\gamma$), hence denoted R'G'B'.

For historical reasons, in order to be backwards compatible with black
and white displays, the raw video file is converted to another colour
space that separates the light information (luma) from the colour
information (chroma), typically referred to as the YUV colour space
family~\cite{poynton-95-color-space}.
Moreover, due to the way the \ac{HVS} works, being more sensible to
light variations than to colour, this family of colour spaces supports
sub-sampling the chroma channels without any major perceptual
degradation.

\subsection{Encoding}
\label{sub:encoding}

This stage is in charge of converting the pre-processed raw video sequence
into a coded video stream to ease the storage and transmission.
A deep look at the inners of a widely used coding scheme is provided
in \S\ref{sec:the_hybrid_video_coding_scheme}.

\subsection{Transmission}
\label{sub:transmission}

The transmission stage stands for the way the encoded bitstream is
transferred to the decoder.
Most typical examples are streaming and storage, which may determine
some of the encoder and decoder behaviours, like real time or memory
constraints.

\subsection{Decoding}
\label{sub:decoding}

As the stream is received by the decoder, it is buffered and used to
reconstruct the encoded data into the appropriate format, as signalled
by the encoder.
Video coding norms tend to define a standard video decoder, which
follows the implemented video coding specification, such as \ac{AVC}
or \ac{HEVC}~\cite{itu-14-h265-hevc-rec,sullivan-12-overview-hevc}.
The encoder must comply to this specification by generating a decodable
stream.

\subsection{Post-processing}
\label{sub:post_processing}

The post-processing stage performs operations for image enhancement and
display adaptation, such as converting back to the original colour
space and to the display format.

\section{The hybrid video coding scheme}
\label{sec:the_hybrid_video_coding_scheme}

State-of-the-art video coding standards such as H.264/\acs{MPEG}-4 \acs{AVC}
and H.265/\acs{HEVC} use a hybrid video coding scheme that appeared in
H.261, in the late eighties.
Since then, all video coding standards and recommendations issued by the
\ac{ITU-T} and the \ac{MPEG} use it as their basic coding structure.

The hybrid video coding scheme is named after its use of both temporal
prediction and transform coding techniques for the prediction error.
A basic structure of the hybrid video coding scheme is presented in
figure~\ref{fig:hybrid_video_coding_scheme}.

\begin{figure}[tb]
	\centering
	\input{./figures/hybrid_video_coding_scheme.tex}
	\caption{Hybrid video coding scheme}
	\label{fig:hybrid_video_coding_scheme}
\end{figure}

The hybrid video coding scheme provides an efficient way of compressing
a video signal into a bitstream of the smallest possible size.
The key features to achieve such a small bitstream are the signal
prediction and the transformation of the prediction error.

The encoder includes a decoder, represented inside a blue box, to be
able to perform its coding decisions based on what the decoder would do
while decoding a bitstream.

The building blocks of the hybrid video coding scheme are explained in
the following subsections.

\subsection{Partitioning}
\label{sub:partitioning}
\index{partitioning}

In order to process the video frames, they are exhaustively partitioned
into non-overlapping blocks.
These blocks ease the succeeding stages of prediction and transform.
The partitioning does not have to be uniform, allowing blocks of different
sizes to be used.
The optimal choice for the block size is left to the encoder.

\begin{figure}[tb]
	\centering
	\includegraphics[width=0.6\linewidth]{./figures/partitioning-orig-all-001.png}
	\caption{Partitioning example using \acs{HEVC} at \acs{QP} 27}
	\label{fig:partitioning}
\end{figure}

\subsection{Prediction}
\label{sub:prediction}

Residual coding is video coding technique based on \ac{DPCM} that,
instead of coding the blocks coming from the original source image
directly, computes an estimation of the block, which is then subtracted
from the original block, generating the residual block.
Those block estimations are carried out by the prediction module, using
some information from previously treated blocks.
This way, predictable information present in the original blocks will be
removed and the energy of the resulting signal will be lowered.

Predictions must be performed the same way at both encoder and decoder
side, and thus computed inside the blue box in
figure~\ref{fig:hybrid_video_coding_scheme}, referring to the decoder.
For this reason, the encoder uses reconstructed blocks (blocks that have
already been encoded and will make it to the bitstream) as the input
data to compute the predictions, because these blocks are equivalent to
those the decoder will handle.

Commonly, predictions might be of two types, depending on the origin of
the prediction source:
intra or spatial prediction for those blocks that
have been predicted using information within the same frame, and inter
or temporal prediction for those blocks predicted using other frames.

\begin{figure}[tb]
	\centering
	\includegraphics[width=0.6\linewidth]{./figures/partitioning-pred-all-001.png}
	\caption{Predicted image}
	\label{fig:predicted_image}
\end{figure}

\begin{figure}[tb]
	\centering
	\includegraphics[width=0.6\linewidth]{./figures/partitioning-resi-all-001.png}
	\caption{Residual image (difference between original and predicted)}
	\label{fig:residual_image}
\end{figure}

\subsubsection{Intra prediction}
\label{ssub:intra_prediction}
\index{intra prediction}

Intra prediction, sometimes referred to as spatial prediction, is used
to remove correlation within local regions of a picture.
The basic principle of intra prediction is that the texture of a picture
region is similar to the texture of its neighbourhood and can be
predicted from there.

The intra prediction is analysed in
Chapter~\ref{cha:the_mode_dependent_directional_transforms}, when
introducing a kind of prediction-adapted transforms.

\subsubsection{Inter prediction}
\label{ssub:inter_prediction}
\index{inter prediction}

Inter prediction, or temporal prediction, takes advantage of the fact
that images close in time share many similarities, and that many of
their component regions will move as a whole.
Since the encoding order is not necessarily the same as the viewing
order, inter predictions can have their origins in either past or future
frames.
Regions that are covered and uncovered by other objects can be predicted
using this technique.

At the encoder side, an extra operation, called motion estimation, is
carried out.
This stage searches for the best matching area in the reference picture
for the current prediction block.
It is one of the most demanding parts of video coders, with regards to
the number of operations.

\subsection{Transform}
\label{sub:transform}

The transform stage removes remaining correlations from the residual
block, computed as the difference between the original and the predicted
blocks.
The goal of the transform is to concentrate the residual energy into as
many few coefficients as possible in the transform domain.

Considering that the subject of this thesis is centred around the
transforms for video coding, the transform stage will be explained
thoroughly in Chapter~\ref{cha:transform_coding}.

\subsection{Quantisation}
\label{sub:quantisation}
\index{QP}\index{lossy}\index{lossless}

The quantisation, applied in the transform domain, it is used to discard
any coefficient whose energy level is below a certain threshold.
High energy coefficients are also be affected by the quantisation.
In standards like \acs{HEVC}, the quantisation step is controlled by a
\ac{QP}.
It is worth noticing that it is the only non-reversible step in the whole
hybrid video coding scheme, and therefore what makes video coding lossy.
Lossless video coding can be attained by not using quantification in the
process.

% \begin{figure}[tb]
% 	\centering
% 	\subfloat[Partitioning]
% 	{\includegraphics[width=0.8\linewidth]{./figures/partitioning-orig-all-001.png}}
% 	\\
% 	\subfloat[Predicted Image]
% 	{\includegraphics[width=0.8\linewidth]{./figures/pred_image-all-001.png}}
% 	\\
% 	\subfloat[Residual Image]
% 	{\includegraphics[width=0.8\linewidth]{./figures/res_image-all-001.png}}
% 	\caption{Example of an image at different encoding points for a
% 	certain level of quantisation}
% 	\label{fig:part_orig_pred_res_image}
% \end{figure}

\subsection{Entropy coding}
\label{sub:entropy_coding}
\index{CABAC}

Once the transform coefficients have been quantised, they have to be
treated to conform the bitstream.
That is, the transform coefficients are scanned to make sure they are
sorted in a way that will make the entropy coder work more efficiently.
Signalling is also conveyed into the bitstream at this point, and the
entropy coder ensures a correct binarisation while using the adequate
number of bits thanks to the \ac{CABAC}.

\section{Encoder control}
\label{sec:encoder_control}

The encoder control is used by essentially all blocks in the diagram
from figure~\ref{fig:hybrid_video_coding_scheme}.
This technique allows the encoder to take decisions related to coding
based on the application requirements.
These decisions include the block sizes and the prediction to use.
For each block size and kind of prediction, the encoder computes the
distortion, using its own decoder, and estimates the rate as illustrated
in figure~\ref{fig:rate_distortion_scheme}.

\begin{figure}[tb]
	\centering
	\input{./figures/rate_distortion_scheme.tex}
	\caption{Rate-distortion scheme of a transform-based codec}
	\label{fig:rate_distortion_scheme}
\end{figure}

\subsection{Distortion measures}
\label{sub:distortion_measures}

\subsubsection{Mean squared error}
\label{ssub:mean_squared_error}
\index{MSE}

The \ac{MSE} is the average of the square difference between two
signals.
For two-dimensional signals, such as images, the \ac{MSE} can be computed as:

\begin{equation}
	MSE_{I,K} = \frac{1}{m\,n} \sum\limits_{i=0}^{m-1} \sum\limits_{j=0}^{n-1}
	{\left[ I(i,j) - K(i,j) \right]} ^2
	\label{eqn:mse}
\end{equation}

Where $I$ and $K$ are two images of $m \times n$ pixels.

\subsubsection{Peak signal-to-noise ratio}
\label{ssub:peak_signal_to_noise_ratio}
\index{PSNR}

The \ac{PSNR} is an objective quality measure that computes the ratio
between the maximum possible value of a signal and the power of the
noise that affects the fidelity of its approximation.
It is usually defined in terms of the logarithmic decibel scale to cope
with the wide range that signals might have.
Defining the \ac{PSNR} in terms of the \ac{MSE} from
\eqref{eqn:mse}, it can be expressed as:
\begin{equation}
	PSNR = 10 \log_{10} \left(\frac{MAX_I^2}{MSE_{I,K}}\right)
	= 20 \log_{10} (MAX_I) - 10 \log_{10} (MSE_{I,K})
	\label{eqn:psnr}
\end{equation}
For 8-bit depth images, $MAX = 2^{8} - 1 = 255$.

\subsection{Rate-distortion optimisation}
\label{sub:rate_distortion_optimisation}
\index{RDO}

In order to carry out the most sensible decision at each time, the
encoder uses a \ac{RDO} criterion
\cite{sullivan-98-rdo-video-compression}.

Each time the encoder has to make a decision about choosing a
particular block size for the partitioning or a prediction mode, it
checks the distortion that decision might cause as well as an estimation
of the bit rate needed.
The encoder performs this computation iteratively the same block,
exploring many different coding possibilities and finally selects the
one that provides the best score in terms of rate and distortion.
This is called the \ac{RDO} loop.

As seen in the previous subsections, computing the distortion is
reasonably straightforward.
However, estimating the bit rate is a bit more delicate, since the whole
entropy coder cannot be run each time the encoder explores the different
possibilities for a block.
As a consequence, an estimation of the bit rate is used in the \ac{RDO}
loop.

\section{Bj{\o}ntegaard Delta measurements}
\label{sub:bjontegaard_delta_measurements}
\index{BD-rate}
\index{BD-PSNR}

Comparing two video coding techniques objectively might be complicated,
as both distortion and bit rate savings have to be taken into account.

Metrics introduced by Gisle Bj{\o}ntegaard, know as \ac{BD} measurements
have become the current \emph{de facto} standard to objectively compare
the result of two encodings~\cite{VCEG-M33,VCEG-AI11}.
Two different metrics are defined and displayed in
figure~\ref{fig:bdsnr_bdrate}:
\begin{enumerate}[label = (\alph{enumi})]
	\item \ac{BD}-\ac{PSNR}: computes the relative quality improvement
		in \deci\bel.
	\item \ac{BD}-rate: computes the relative savings in bit rate for an
		equivalent distortion in percent.
\end{enumerate}

\begin{figure}[tb]
	\centering
	\subfloat[\acs{BD}-\acs{PSNR}]
	{\includegraphics{./figures/bd_psnr_plot.pdf}}
	\hfill
	\subfloat[\acs{BD}-rate]
	{\includegraphics{./figures/bd_rate_plot.pdf}}
	\caption{Schematic representation of rate-distortion plots using the
	\ac{BD} measurements}
	\label{fig:bdsnr_bdrate}
\end{figure}

\section{Conclusions}
\label{sec:conclusions_video_coding}

This chapter has presented the motivation for video coding as well as
some general concepts concerning an overview of the video coding system.

Current video coders exploit both redundancies existing within images of
the video sequence via predictions.
These predictions can be either spatial or temporal, depending on
whether the prediction source is the same image or another image,
respectively.
Unpredictable parts of the image, called residuals, are then transformed
in order to concentrate their energy in as few coefficients as possible.

Next chapter will explore the details of the transforms used in video
coding, namely their design principles and a comparison between two
design approaches.

\chapter{Transform coding}
\label{cha:transform_coding}
\chaptertoc

\section{Introduction to transforms}
\label{sec:introduction_to_transforms}

In the previous chapter, transforms were mentioned as an important part
in current video coders.
This chapter will study their design and properties that lead transforms
to be useful in video coding.

A transform is a mathematical operation that takes an input signal and
represents the same input signal in a different domain.

High energy compaction provided by transform coding has led this
technique to be present in the international video coding standards.

Transform coding allows removing existing signal correlations in the
spatial domain, leading to a decorrelated signal in the transform
domain.
This is of great importance for the upcoming stages of scanning and
entropy coding.

Transforms can be very abstract since they tend to work in N-dimensional
spaces.
However, restraining ourselves to two dimensions, one of the most visual
and representative example of transforms are rotations.
The example in figure~\ref{fig:transform_rotation} helps visualising the
transform role in signal compression.

\begin{figure}[tb]
	\centering
	\includegraphics{./figures/transform_rotation_plot.pdf}
	\caption{Simple transform performing a rotation}
	\label{fig:transform_rotation}
\end{figure}

Whereas on the left signal (in blue), both the horizontal and vertical
dimensions are needed to describe the signal completely, on the right
signal (in red), the vertical dimension is enough to provide an equally
accurate signal representation, since the horizontal dimension remains
constant.

\subsection{Block-based transforms}
\label{sub:block_based_transforms}

Amongst all the different kinds of transforms available, the ones used
in image and video coding applications are the block-based transforms
due to the good trade-off they provide in terms of complexity and
performance.

\subsection{Separability}
\label{sub:separability}

Image and video coding deal with image blocks, which are two-dimensional
signals and, consequently, use transforms able two process those
signals.

The naive approach to work with those signals is to use non-separable
transforms.
These transforms take the signal as a whole and reshape it to a
single-dimensional signal.
Afterwards the transform is applied normally:
\begin{equation}
	\X = \A \, \x
\end{equation}
where $\x$ is a $N \times N$ block, reshaped into a $N^2\times1$ vector
and $\A$ is a $N^2 \times N^2$ matrix.
The main disadvantage of this approach is the number of calculations
required to obtain the transformed signal: for a $N \times N$ block, the
number of operations required to transform it in a non-separable way is:
$N^4$ multiplications and $N^2(N^2-1)$ additions.

Due to the high amount of operations needed to transform a block,
separable transforms are widely used in video coding.
They are computed as:
\begin{equation}
	\X = \A {\left(\A \, \x^T\right)}^T = \A \, \x \, \A^T
\end{equation}
where $\x$ is a $N \times N$ block and the transform $\A$ is a $N \times
N$ matrix.
The operation inside the parenthesis transforms the rows of $\x$, and
the outter part, the columns of $\x$.
By perfoming the horizontal and vertical transforms separably, the
number of operations required has been reduced to $2N^3$ multiplications
and $2N^2(N-1)$ additions.

However, this reduction in complexity comes at a price: non-separable
transforms were able to exploit any correlation amongst pixels within a
block, whether separable transforms can only decorrelate pixels that
share the same row or column.
In other words, separable transforms are less performing than their
non-separable counterparts.
The impact in performance due to separability will be studied in detail
in Chapter~\ref{cha:the_mode_dependent_directional_transforms}.

\subsection{Transform design}
\label{sub:transform_design}

Since the objective of the transforms is to be able to represent the
signal with as few coefficients as possible while minimising the
distortion introduced by the quantisation, transform design methods are
often a trade-off between the distortion and the number of bits needed
to represent those signals in the transform domain.

Many transform design methods agree on how the distortion should be
computed, namely using the \ac{MSE} from~\eqref{eqn:mse}.
However, different transform designs exist depending on the used rate
model.
Next sections will study different transform design approaches based on,
amongst others, different modellings of the rate constraint.
\begin{equation}
	J(\lambda) = \text{Distortion} + \lambda \text{Rate}
	\label{eqn:transform_design}
\end{equation}

\section{The Karhunen-Lo√®ve transform}
\label{sec:the_karhunen_loeve_transform}
\index{KLT}
In general, the components of source signals are correlated with one
another.
However, it is indeed, possible to select an orthogonal matrix $\A$, for
a given \ac{PDF} describing the source that will make $\X=\A\x$ have
pairwise uncorrelated components~\cite{gersho-92-vector-quantization}.
The \ac{KLT} is a linear transform that removes the redundancy by
decorrelating the data, so that the signal can be stored more
efficiently~\cite{rao-01-transform-data-compression-book}.

The \ac{KLT} is often presented as the optimal transform in a general
case, sometimes even for all possible sources of signals.
However, it has been proved to be suboptimal in the transform coding /
bit allocation sense~\cite{effros-04-suboptimal-klt}.

In this section, the \ac{KLT} is presented under its well-known optimal
conditions: Gaussian sources with high resolution quantisation
assumptions~\cite{goyal-00-high-resolution}.
The high resolution assumption states that the number of quantisation
levels $N$ is very high, the maximum quantisation step size
$\Delta_{\max}$ is sufficiently small compared to the range of the
granular region and the \ac{PDF} is relatively smooth.
This means that, for a specific \ac{PDF}, increasing $N$ directly
implies that $\Delta_{\max}$ decreases inversely with $N$.
Under those conditions, the \ac{KLT} is the optimal transform in terms
of bit allocation that minimises the overall
distortion~\cite{gersho-92-vector-quantization}.

Since the \ac{KLT} decorrelates the signal in the transform domain, it
can be computed as follows.
Let $\x$ be a zero-mean Gaussian process and $\A$ an orthonormal transform.
In the transform domain:
\begin{equation}
	\X = \A \x \qquad \text{s.t. } \A \A^T = \I
\end{equation}
The covariance matrix in the transform domain is expressed as:
\begin{equation}
	\C_\X = \E\left\{\X \X^T\right\} = \A \E\left\{\x\x^T\right\}\A^T =
	\A\C_\x\A^T
\end{equation}
Or equivalently:
\begin{equation}
	\A^T\C_\X = \C_\x\A^T
\end{equation}
And since $\C_\X$ is diagonal by construction:
\begin{equation}
	\C_\x \a_i = \lambda_i\a_i
\end{equation}
Where:
\begin{itemize}
	\item $\a_i$ are the eigenvectors of $\C_\x$.
	\item $\lambda_i$ are the eigenvalues of $\C_\x$.
\end{itemize}

\subsection{Particular case on natural images: the \acs{DCT}}
\label{sub:particular_case_dct}
\index{DCT}
\index{Markov}
\index{AR}
\index{Toeplitz matrix}

One of the most used transforms in image and video coding is the
\ac{DCT}.
In this section, the \ac{DCT} will be justified over a particular kind
of signals: natural images.
Natural images exhibit a first order \ac{AR} structure.
A first order \ac{AR} model, also known as Markov-1 process, is a
stochastic process that can be generated through the following
regression formula:
\begin{equation}
	x(n) = \rho x(n-1) + w(n)
	\label{eqn:first_order_ar_model}
\end{equation}
Where $\rho$ is the correlation coefficient between two adjacent samples
and $w(n)$ is a white noise with zero mean, whose variance is related to
the variance of $x(n)$ $\sigma_x^2$ as:
\begin{equation}
	\sigma_w^2 = \E\left\{ w(n) w(n) \right\} =
	\left(1-\rho^2\right)\sigma_x^2
\end{equation}
The correlation matrix of this process takes the form of a Toeplitz
matrix~\cite{akansu-12-toeplitz-approximation}:
\begin{equation}
	\R_x = \sigma_x^2
	\begin{pmatrix}
		1          & \rho       & \rho^2     & \cdots & \rho^{N-1} \\
		\rho       & 1          & \rho       & \cdots & \rho^{N-2} \\
		\rho^2     & \rho       & 1          & \cdots & \rho^{N-3} \\
		\vdots     & \vdots     & \vdots     & \ddots & \vdots     \\
		\rho^{N-1} & \rho^{N-2} & \rho^{N-3} & \cdots & 1
	\end{pmatrix}
	\label{eqn:toeplitz_matrix}
\end{equation}
The \ac{KLT} for this kind of processes, that is, the eigenvectors of
$\R_\x$, tends to the \ac{DCT} as $\rho\to1$~\cite{britanak-06-dct-and-dst}.
The \ac{DCT}-II can be expressed compactly as:
\begin{equation}
	{\left[C_{N}^{II} \right]}_{n,k} =
	\sqrt{\frac{2}{N}}\epsilon_k\cos\left(\frac{\pi(2n+1)k}{2N}\right)
	\quad
	n,k=0,\dots,N-1
	\label{eqn:dct_ii}
\end{equation}

\begin{equation}
	\epsilon_k =
	\begin{cases}
		\frac{1}{\sqrt{2}} & k = 0 \\
		1 & \text{otherwise}
	\end{cases}
\end{equation}

The fact that the \ac{DCT} approximates the \ac{KLT} for a wide variety
signals and its efficient implementation have made it the preferred
choice in image and video compression algorithms to decorrelate the
signals and concentrate their energy into few
coefficients~\cite{sole-12-transform-coefficient-coding}.

\begin{figure}[tb]
	\centering
	\subfloat[\acs{DCT}-II $4\times4$]
	{\includegraphics[width=0.3\linewidth]{./figures/dct4-bases.png}}
	\hspace{0.2\linewidth}
	\subfloat[\acs{DST}-VII $4\times4$]
	{\includegraphics[width=0.3\linewidth]{./figures/dst4-bases.png}}
	\caption{Transforms used in \ac{HEVC} for $4\times4$ blocks}
	\label{fig:dct_dst}
\end{figure}

\subsection{Particular case on prediction residuals: the \acs{DST}}
\label{sub:particular_case_dst}
\index{DST}
\index{intra prediction}
\index{tridiagonal matrix}
\index{Toeplitz matrix}

Although the \ac{DCT} has been proved to be nearly the \ac{KLT} for natural
images, it is used in predictive transform coding based video standards, as
well.
This kind of coding leads to signals whose nature differs from that of
natural images: prediction residuals.
In particular, prediction residuals resulting from intra prediction tend
to have particular properties.
Those residuals are computed using predictions from already
reconstructed blocks, usually available on the left and upper borders of
the current residual, as shown in figure~\ref{fig:pred_scheme}.a.
An example of a prediction residual is provided in
figure~\ref{fig:pred_scheme}.b.
It can be noticed that the energy of the residual is lower (dark) near
the borders where reconstructed blocks are available, and that the error
gets higher (lighter) as one moves away from the boundaries.
These facts motivated a study on this particular kind of blocks,
resulting in a transform that performs better on them than the \ac{DCT}:
the \ac{DST}~\cite{han-10-spatial-adaptive-transform}.
\begin{figure}[tb]
	\centering
	\subfloat[Intra prediction modes for the current block (white) from
	previously reconstructed blocks (grey)]
	{\input{./figures/pred-scheme.tex}}
	\hspace{0.2\linewidth}
	\subfloat[Average intra prediction residual]
	{\includegraphics[width=0.3\linewidth]{./figures/resids-scan-diag.png}}
	\caption{Prediction scheme showing all intra prediction modes and a
	prediction residual example}
	\label{fig:pred_scheme}
\end{figure}

These kind of signals present a correlation matrix that can be modelled
using a Toeplitz tridiagonal matrix, as the one
in~\eqref{eqn:tridiagonal_matrix}.
Note that a tilde has been used to indicate that the bottom-right corner
value of the matrix has been modified in order to elimnate the
irregularity (used to be 1) and be able to compute the eigenvectors
analytically~\cite{han-10-spatial-adaptive-transform,
yueh-05-eigenvalues-tridiagonal}.
\begin{equation}
	\tilde\R_x =
	\begin{pmatrix}
		1+\rho^2 & -\rho    & 0        & 0      & \hdots & 0            \\
		-\rho    & 1+\rho^2 & -\rho    & 0      & \hdots & 0            \\
		0        & -\rho    & 1+\rho^2 & -\rho  & \hdots & 0            \\
		0        & \ddots   & \ddots   & \ddots & \ddots & \vdots       \\
		\vdots   & \ddots   & \ddots   & \ddots & \ddots & -\rho        \\
		0        & \hdots   & 0        & 0      & -\rho  & 1+\rho^2-\rho
	\end{pmatrix}
	\label{eqn:tridiagonal_matrix}
\end{equation}
Those eigenvalues can be expressed in a closed form using the
\ac{DST}-VII from~\eqref{eqn:dst_vii}.
\begin{equation}
	{\left[S_{N}^{VII} \right]}_{n,k} =
	\frac{2}{\sqrt{2N+1}}\sin\left(\frac{\pi(2n-1)k}{2N+1}\right),
	\quad
	n,k = 1, \dots, N
	\label{eqn:dst_vii}
\end{equation}

Figure~\ref{fig:dct_dst}.b presents the \ac{DST}-VII bases for
$4\times4$ blocks.
The resemblance between an average residual block
from figure~\ref{fig:pred_scheme}.b can be spotted by comparing it to
the first base vector from the \ac{DST}.

The use of the \ac{DST} in \ac{HEVC} over the \ac{DCT} on $4\times4$
blocks leads to a bit-rate reduction of 1\% on
average~\cite{sullivan-12-overview-hevc}.
An explanation on how it was discovered that the \ac{DST} was a good
approximation of the \ac{KLT} for these signals is detailed in
Chapter~\ref{cha:the_mode_dependent_directional_transforms}, more
precisely in \S\ref{sec:the_story_behind_the_dst}.

\section{The rate-distortion optimised transform}
\label{sec:the_rate_distortion_optimised_transform}
\index{RDOT}

State-of-the-art video coding standard, such as \ac{HEVC} take advantage
of sparse signals.
As discussed before, transforms try to concentrate the energy of the
residuals into as few coefficients as possible, maximising the number of
zeroes in the transform domain.
There are even syntax elements in \ac{HEVC} to deal with this:
for a given transformed residual, the position of the last non-zero
value is indicated, meaning that from that point onwards, all the
following values are zero.

In order to better fit the video coding demands, Sezer proposes a kind
of transforms that take into account the sparsity of the output in their
design~\cite{sezer-11-phd}.
The proposed \ac{RDOT} can be expressed as:
\begin{equation}
	\A_{opt} = \arg\min\limits_{\A}
	\sum_{\forall i} \min\limits_{\c_i}
	\left(
	{\Vert \x_i - \A^T\c_i \Vert}_2^2 + \lambda\overline{\Vert \c_i \Vert}_0
	\right)
	\label{eqn:rdot-nsep}
\end{equation}
Where $\x_i$ are the input signals, i.e.\ a block of the training set,
$\c_i$ are its quantised transformed coefficients using the transform
$\A$.
$\A^T$ is its transposed matrix, as $\A$ is chosen orthonormal.
The constraint in the cost function is the average $\ell_0$ norm of the
coefficients, i.e.\ the number of non-zero coefficients.
Finally, $\lambda$ is the Lagrange multiplier of the constraint.

A thorough study of~\eqref{eqn:rdot-nsep} analysing its properties and
consequences is detailed below.

\subsection{The \acs{RDOT} metric}
\label{sub:the_rdot_metric}

The value that \acp{RDOT} minimise is expressed
in~\eqref{eqn:rdot_metric} for a single signal.
This metric depends exclusively on the quantisation step $\Delta$ and the
initial transform used $\A$.
The relation between the Lagrange multiplier $\lambda$ and $\Delta$ is
detailed in \S\ref{sub:the_lagrange_multiplier}.
\begin{equation}
	J (\lambda) =
	{\Vert \x - \A^T \c \Vert}_2^2 + \lambda\overline{\Vert \c \Vert}_0
	\label{eqn:rdot_metric}
\end{equation}
The first part of the equation represents the distortion introduced by
the quantisation.
The second term serves as rate-like constraint, by ensuring that the
number of significant values in the transform domain is minimised,
together with the distortion.

The minimisation of the metric happens in two steps, carried out iteratively
until convergence:
\begin{enumerate}
	\item Finding the optimal coefficients for a given transform.
	\item Updating the transform for the optimal coefficients.
\end{enumerate}

\subsubsection{Optimal coefficients for a given transform}
\label{ssub:optimal_coefficients_for_a_given_transform}

The optimal coefficients are obtained by transforming the signal and
hard-thresholing them:
\begin{equation}
	\c = \lfloor \X \rfloor = \lfloor \A \x \rfloor
\end{equation}
The threshold value is tightly related to the Lagrange multiplier $\lambda$,
as demonstrated in\S~\ref{sub:the_lagrange_multiplier}:
\begin{equation}
	\c[n] =
	\begin{cases}
		\X[n] & \vert \X[n] \vert \ge \displaystyle \frac{\Delta}{2} \\
		0     & \text{otherwise} \\
	\end{cases}
	\label{eqn:hard_threshold}
\end{equation}

\subsubsection{Optimal transform for given coefficients}
\label{ssub:optimal_transform_for_given_coefficients}

Once the optimal coefficients have been found, the transform $\A$ must
be updated to provide the mapping between $\x$ and $\c$ while minimising
the reconstruction error.
\begin{equation}
	\A_{opt} = \arg\min\limits_{\A}
	\left(
	\sum_{\forall i}{\Vert \x_i - \A^T\c_i\Vert}^2
	\right)
	\qquad \text{s.t. } \A\A^T = \I
\end{equation}
Since the expression represents a scalar value, it can be rewritten
using the trace:
\begin{equation}
	\A_{opt} = \arg\min\limits_{\A}
	\left(\sum_{\forall i}\tr\left( 
	{\left(\x_i - \A^T\c_i\right)}^T\left( \x_i - \A^T\c_i\right)
	\right)\right)
\end{equation}
Operating:
\begin{equation}
	\A_{opt} = \arg\min\limits_{\A}
	\left(\sum_{\forall i}\tr\left( 
	\x_i^T\x_i -\x_i^T\A^T\c_i -\c_i^T\A\x_i^T + \c_i^T\A\A^T\c_i
	\right)\right)
\end{equation}
Since the trace is a linear operator and $\A\A^T=\I$:
\begin{equation}
	\A_{opt} = \arg\min\limits_{\A}
	\left(\sum_{\forall i}
	\tr\left(\x_i^T\x_i\right)
	-\tr\left(\x_i^T\A^T\c_i\right)
	-\tr\left(\c_i^T\A\x_i^T\right)
	+\tr\left(\c_i^T\c_i \right)
	\right)
\end{equation}
Making use of the cyclic property of the trace and removing
$\A$-independent terms:
\begin{equation}
	\A_{opt} = \arg\min\limits_{\A}
	\left(\sum_{\forall i}
	-2\tr\left(\c_i\x_i^T\A^T\right)
	\right)
\end{equation}
We now define $\Y=\displaystyle\sum_{\forall i}\c_i\x_i^T$ and its SVD
decomposition $\Y=\U\Lambdab^{\nicefrac{1}{2}}\V^T$, where $\U$ and $\V$
are orthonormal and $\Lambdab$ is diagonal.
The equation rewrites as follows:
\begin{equation}
	\A_{opt} = \arg\min\limits_{\A}
	\left(
	-2\tr\left(\U\Lambdab^{\nicefrac{1}{2}}\V^T\A^T\right)
	\right)
\end{equation}
Minimising a negative expression is equivalent to maximise its positive
version.
Re-arranging the terms using the trace cyclic property:
\begin{equation}
	\A_{opt} = \arg\min\limits_{\A}
	\left(
	-2\tr\left(\Lambdab^{\nicefrac{1}{2}}\V^T\A^T\U\right)
	\right)
\end{equation}
Let $\Pb=\V^T\A^T\U$. Since $\V$, $\A$ and $\U$ are orthonormal, so is
$\Pb$. The equation is now:
\begin{equation}
	\A_{opt} = \arg\max\limits_{\A}
	\left(
	\tr\left(\Lambdab^{\nicefrac{1}{2}}\Pb\right)
	\right)
\end{equation}
Since $\Lambdab$ is a diagonal matrix whose entries are non-negative by
definition and $\Pb$ is orthonormal, the maximisation is achieved when
$\Pb=\I$
\begin{equation}
	\V^T\A_{opt}^T\U=\I\quad \Rightarrow \quad \A_{opt} = \U\V^T
\end{equation}

Summing up, the optimal transform is obtained using the SVD decomposition of
the cross-correlation matrix of the output signal (the transformed and
quantised coefficients) with the input signal (the intra prediction
residuals).

\subsection{The Lagrange multiplier and the zero norm}
\label{sub:the_lagrange_multiplier}
\index{generalised normal distribution}
\index{generalised Gaussian distribution}
\index{exponential power distribution}

It is a well-known fact that the residuals distribution can be modelled
using a \ac{GGD}, also known as generalised normal distribution or
exponential power
distribution~\cite{lam-00-dct-coefficient-distribution,
yovanof-96-analysis-dct-coefficients}.
For this reason, in order to obtain the optimal Lagrange multiplier in a
reasonably general case, a \ac{GGD} will be used to represent the
residuals \ac{PDF}.

Figure~\ref{fig:probability_density_functions} illustrates the \acp{PDF}
of a set of residuals transformed with the \ac{DCT} and the same residuals
transformed with an adapted \ac{RDOT}.
As expected, the use of an adapted transform has increased the number
of zeroes in the transform domain and, consequently, lowered the amount
of values elsewhere.
Changing the transform, modifies the resulting \ac{PDF}, but
since the used transforms are orthonormal, the variance remains
unaltered.
Residuals are computed as the difference between predicted and original
blocks, meaning they are prediction errors.
These errors are made by excess or defect evenly, evidenced by their
zero-mean \ac{PDF}.
\begin{figure}[tb]
	\centering
	\includegraphics{./figures/pdfs_plot.pdf}
	\caption{\acsp{PDF} of the residuals with different transforms
	compared to Laplace and normal distributions}
	\label{fig:probability_density_functions}
\end{figure}
Figure~\ref{fig:probability_density_functions} also includes the
\ac{PDF} of a Laplace distribution and a normal distribution.
Those two distribution are particular cases of a \ac{GGD}.

The centred \ac{GGD} \ac{PDF} can be expressed compactly as:
\index{gamma function}
\begin{equation}
	\GGD(\sigma,\gamma,x)=
	a\e^{-{\left(b\vert x \vert\right)}^\gamma}
	\label{eqn:ggd}
\end{equation}
Where:
\begin{align}
	b &= \frac{1}{\sigma}\sqrt{
	\frac{\Gamma\left(\nicefrac{3}{\gamma}\right)}
	{\Gamma \left(\nicefrac{1}{\gamma}\right)}} \\
	a &= \frac{b\gamma}{2\Gamma \left(\nicefrac{1}{\gamma}\right)}
\end{align}
and $\Gamma(z)$ is the gamma function, defined as:
\begin{equation}
	\Gamma(z) = \int_0^\infty t^{z-1}\e^{-t}\d t
\end{equation}
\index{Laplace distribution}
\index{Gaussian distribution}
\index{normal distribution}
\index{uniform distribution}
The Laplace and normal or Gaussian \acp{PDF} are achieved with
$\gamma=1$ and $\gamma=2$, respectively.
Even the uniform distribution can be reached by making $\gamma\to\infty$.
However, from figure~\ref{fig:probability_density_functions} one can see
that $1\le\gamma\le2$ for video residuals.

In Sezer's work~\cite{sezer-11-phd,sezer-08-sparse-orthonormal-transforms},
the optimal value of the Lagrange multiplier $\lambda$ has been claimed
to be straightforward to obtain.
However, no analytical way of proving its optimality has been found in
literature.
Hence, a complete study has been carried out below.

In order to find the optimal $\lambda$ from~\eqref{eqn:rdot_metric},
which describes the trade-off between the distortion and the rate,
$J(\lambda)$ has to be derived.
The problem will be tackled in two separate steps:
\begin{enumerate}
	\item Compute the distortion analytically and derive it.
	\item Compute the rate constraint and derive it.
\end{enumerate}

\subsubsection{Derivation of the distortion function}
\label{ssub:derivation_of_the_distortion_function}

The distortion introduced by the hard-thresholding
from~\eqref{eqn:hard_threshold} can be expressed as:
\begin{equation}
	D
	= \int_{-\infty}^{\infty} {(x - \hat x)}^2 \P_X (x)\d x
	= \int_{\nicefrac{-\Delta}{2}}^{\nicefrac{\Delta}{2}}
	\label{eqn:int_distortion}
	x^2\P_X (x) \d x
\end{equation}
Note that the integration intervals have been reduced to where the
quantised values differ from the original ones, that is, the values that
have been affected by the hard-thresholding from
\eqref{eqn:hard_threshold}.

Substituting $P_X(x)$ by the residuals \ac{PDF}:
\begin{align}
	D
	&=\int_{\nicefrac{-\Delta}{2}}^{\nicefrac{\Delta}{2}}
	x^2 a \e^{-{\left(b\vert x \vert\right)}^\gamma} \d x \\
	&=2 \int_0^{\nicefrac{\Delta}{2}}
	x^2 a \e^{-{\left(b x \right)}^\gamma} \d x\\
	&=
		2a \frac{\Gamma\left(\frac{3}{\gamma}\right)-
		\Gamma\left(
		\frac{3}{\gamma},{\left(\frac{b\Delta}{2}\right)}^\gamma
		\right)}{b^3\gamma}
	\label{eqn:distortion}
\end{align}
Where $\Gamma(a,z)$ is the incomplete upper gamma function, defined as:
\index{incomplete upper gamma function}
\begin{equation}
	\Gamma(a,z)=\int_z^\infty t^{a-1}\e^{-t}\d t
\end{equation}
Deriving~\eqref{eqn:distortion} in $\Delta$:
\begin{equation}
	\frac{\d D}{\d\Delta} =
	\frac{\Delta^2 a \e^{{(-b\nicefrac{\Delta}{2})}^\gamma}}{4}
	\label{eqn:diff_distortion}
\end{equation}

\subsubsection{Derivation of the zero norm function}
\label{ssub:derivation_of_the_zero_norm_function}

By definition, the $\ell_0$ norm is the total number of non-zero
elements in a vector.
Consequently, the constraint can be expressed as:
\begin{equation}
	R 
	= \overline{\Vert \c \Vert}_0 = \frac{1}{N}{\Vert \c \Vert}_0
	= \frac{1}{N} N \P_X\left(\vert X \vert \ge \frac{\Delta}{2}\right)
	= 1-P_X\left(\vert X \vert < \frac{\Delta}{2}\right)
	= 1-\int_{\nicefrac{-\Delta}{2}}^{\nicefrac{\Delta}{2}}\P_X(x)\d x
	\label{eqn:int_rate}
\end{equation}
Substituting $P_X(x)$ by the residuals \ac{PDF}:
\begin{align}
	R
	&=1-\int_{\nicefrac{-\Delta}{2}}^{\nicefrac{\Delta}{2}}
	a \e^{-{\left(b\vert x \vert\right)}^\gamma} \d x \\
	&=1-2\int_0^{\nicefrac{\Delta}{2}}
	a \e^{-{\left(b x \right)}^\gamma} \d x \\
	&=1+2a\frac{\Gamma\left(
		\frac{1}{\gamma},{\left(\frac{b\Delta}{2}\right)}^\gamma\right)-
		\Gamma\left(\frac{1}{\gamma}\right)}
		{b\gamma}
	\label{eqn:rate}
\end{align}
Deriving~\eqref{eqn:rate} in $\Delta$:
\begin{equation}
	\frac{\d R}{\d\Delta} =
	-a\e^{{\left(\nicefrac{-b\Delta}{2}\right)}^\gamma}
	\label{eqn:diff_rate}
\end{equation}
\subsubsection{Optimal Lagrange multiplier}
\label{ssub:optimal_lagrange_multiplier}

With both the distortion~\eqref{eqn:diff_distortion} and the
constraint~\eqref{eqn:diff_rate} derived, the optimal Lagrange
multiplier can be found as:
\begin{equation}
	\frac{\d J(\lambda)}{\d \Delta}
	= \frac{\d D}{\d \Delta} +
	\lambda \frac{\d R}{\d \Delta} = 0 \\
	\label{eqn:diff_lagrange_multiplier}
\end{equation}
Substituting both derivatives:
\begin{equation}
	\frac{\Delta^2 a \e^{{(-b\nicefrac{\Delta}{2})}^\gamma}}{4}
	- \lambda
	a\e^{{\left(\nicefrac{-b\Delta}{2}\right)}^\gamma} = 0
	\quad \Rightarrow \quad \boxed{\lambda = \frac{\Delta^2}{4}}
\end{equation}

This proves how the Lagrange multiplier is only related to the
quantisation step.
In other words, once the quantisation step is fixed, so is the optimal
balance between the distortion and the rate constraint.

An important consequence of using the $\ell_0$ norm is that the optimal
Lagrange multiplier is independent from the data's \ac{PDF} (it doest
not depend on $\sigma$ neither on $\gamma$), meaning that the optimal
Lagrange multiplier remains the same, no matter which transform has been
used.
In fact, these results can be generalised to any \ac{PDF}, making the
$\ell_0$ norm a robust approximation of the rate, suitable for this
iterative learning method, where the transform changes at each iteration
and so does the \ac{PDF} of the training data.

\subsection{Independence from the \ac{PDF}}
\label{sub:independence_from_the_pdf}

In the previous subsection, for a given quantisation step, the value of
the optimal Lagrange multiplier $\lambda$ has been proved for the
particular case of the residuals displaying \ac{PDF} that can be
modelled after a \ac{GGD}.
By using the fundamental theorem of calculus, which relates integrals
and derivatives of a function, one can generalise that conclusion for
any continuous \ac{PDF}.

Let $f(x)$ be the residuals \ac{PDF}.
The distortion is computed reusing~\eqref{eqn:int_distortion}:
\begin{equation}
	D = \int_{\nicefrac{-\Delta}{2}}^{\nicefrac{\Delta}{2}} x^2 f(x) \d x
\end{equation}
Deriving the distortion with respect to $\Delta$:
\begin{equation}
	\frac{\d D}{\d \Delta} =
	\frac{\Delta^2}{8}\left[
	f\left(\frac{\Delta}{2}\right)+f\left(-\frac{\Delta}{2}\right)\right]
\end{equation}
The rate constraint from~\eqref{eqn:int_rate} is computed as
follows with the generic \ac{PDF}
$f(x)$:
\begin{equation}
	R = 1 - \int_{\nicefrac{-\Delta}{2}}^{\nicefrac{\Delta}{2}} f(x) \d x\\
\end{equation}
Again, deriving with respect to $\Delta$:
\begin{equation}
	\frac{\d R}{\d \Delta} =
	-\frac{1}{2}\left[
	f\left(\frac{\Delta}{2}\right)+
	f\left(-\frac{\Delta}{2}\right)\right]
\end{equation}
Combining previous equations using~\eqref{eqn:diff_lagrange_multiplier},
one can see that the optimal Lagrange multiplier $\lambda$ does not
depend on the residuals \ac{PDF}:
\begin{equation}
	\frac{\Delta^2}{8}\left[
	f\left(\frac{\Delta}{2}\right)+f\left(-\frac{\Delta}{2}\right)\right]
	- \lambda
	\frac{1}{2}\left[
	f\left(\frac{\Delta}{2}\right)+
	f\left(-\frac{\Delta}{2}\right)\right] = 0
\end{equation}
\begin{equation}
	\boxed{\lambda = \frac{\Delta^2}{4}}
\end{equation}

This fact makes the $\ell_0$ norm suitable even for distributions
that can not be modelled after a \ac{GGD}.
The independence from the \ac{PDF} reassures the choice of the $\ell_0$
norm over other models that might provide a more realistic and accurate
approximation of the rate, such as the \ac{H}.

An example of the $\ell_0$ norm independence from the \ac{PDF} is provided
below.
Consider the following scenario: some residuals \acp{PDF} that follow
\ac{GGD} with different exponents $\gamma$.
Consider, as well, a quantisation step $\Delta=14.256$, issued from a
\ac{QP} 27 in \ac{HEVC}.
It has been proved previously, that $J(\lambda)$
from~\eqref{eqn:rdot_metric} has achieves its minimum value at
$\lambda=\frac{\Delta^2}{4}\approx50.81$, independently from the
residuals \ac{PDF} when modelling the rate with the $\ell_0$ norm.

However, if instead of using the $\ell_0$ norm, entropy is used, it can
no longer be assumed that the optimal value of $\lambda$ providing the
best trade-off between distortion and rate does not depend on the
residuals \ac{PDF}.
Due to the complexity of the calculations involved then using the
entropy together with a uniform quantiser, the dependence to the
\ac{PDF} will be evidenced through the example from
figure~\ref{fig:j_lambda_qp}, where the value $J(\lambda)$ is plotted
for various \acp{GGD} at different \ac{QP} values, i.e.\ quantisation
step $\Delta$.
When using the $\ell_0$ norm, $J(\lambda)$ reaches its minimum value at
QP 27, as expected.
On the other hand, using the entropy leads to a minimum value of
$J(\lambda)$ that is \ac{PDF}-dependent.
An unwanted consequence of this dependence is that, for an iterative
learning algorithm, after updating the transform at each iteration, the
new \ac{PDF} has to be estimated to find the new optimal Lagrange
multiplier $\lambda$, complicating the whole learning process and
leading to possible instabilities.
\begin{figure}[tp]
	\centering
	\includegraphics{./figures/j_qp27_plot.pdf}
	\caption{$J(\lambda)$ for different \acp{GGD} modelling the rate with
	the $\ell_0$ norm and the entropy (H)}
	\label{fig:j_lambda_qp}
\end{figure}

\subsection{Rate-distortion improvement through the learning}
\label{sub:rate_distortion_improvement_through_the_learning}

Assuming the source \ac{PDF} can be modelled after a \ac{GGD} with a
given variance $\sigma^2$ and exponent $\gamma$, the impact of the
learning in terms of the $J(\lambda)$ from~\eqref{eqn:rdot_metric} can
be illustrated with the following example.
By learning an adapted transform over a set of residuals, the amount of
transformed coefficients mapped to zero increases, augmenting its
kurtosis (the distribution ``looks more sharp''), hence reducing the
exponent $\gamma$.
Figure~\ref{fig:j_lambda_qp} illustrates how the relationship between
the distortion and the rate model, at different \acp{QP}.
\acp{QP} 27 and 32 are highlighted, corresponding to quantisation steps
$\Delta = 14.256$ and $\Delta = 25.504$ in \ac{HEVC} respectively.

\begin{figure}[tp]
	\centering
	\includegraphics{./figures/dist_zero_qp_plot.pdf}
	\caption{Distortion and $\ell_0$ norm with $\lambda_{opt}$ at
	\acsp{QP} 27 and 32 for different \acsp{PDF}}
	\label{fig:lambda_zero_norm_dist}
\end{figure}

As the exponent $\gamma$ decreases, so do both terms of $J(\lambda)$,
the distortion and the $\ell_0$ norm.
It can also be seen that since the Lagrange multiplier value $\lambda$
does not change, neither does the slope of a tangent line to the circled
points, corresponding to the optimal trade-off between the distortion
and the rate constraint.
The amount of improvement in each direction is weighed by $\lambda$: at
\ac{QP} 27 there is more room for sparsity improvement than there is for
reducing the distortion, compared to \ac{QP} 32.

\section{Conclusions}
\label{sec:conclusions_transforms}

This chapter has introduced different types of transforms and some
basic concepts, such as separability and its relation to computational
complexity.

Two completely different approaches of transform design have been
studied: the \ac{KLT} and the \ac{RDOT}.
The \ac{KLT} defines the optimal transform for Gaussian sources with a
high resolution hypothesis.
The \ac{DCT} and \ac{DST} used in \ac{HEVC} have been obtained as the
\ac{KLT} for particular kinds of signals.

The \ac{RDOT} finds the optimal balance between the distortion
introduced and a rate constraint.
A thorough study on its design has been carried out to justify the
appropriateness of the approach over other learning methods.

In the next chapter, both transform designs will be tested in a real
scenario to find out their performances in video coding.


\chapter{The mode-dependent directional transforms}
\label{cha:the_mode_dependent_directional_transforms}
\chaptertoc

\section{Introduction to intra prediction modes in \acs{HEVC}}
\label{sec:introduction_to_intra_prediction_modes_in_hevc}

As seen in Chapter~\ref{cha:video_coding_fundamentals}, \ac{HEVC} makes
use of predictions in order to generate a low signal energy, called
residual, and improve the coding efficiency.
With regards to previous standards, such as H.264/\ac{MPEG}-4 \ac{AVC},
which had 9 different prediction modes for intra coding, \ac{HEVC} has
an improved prediction system, with 35 different prediction modes.
Figure~\ref{fig:mdcs} illustrates those prediction modes.
A detailed explanation on how predictions are derived from those
prediction mode can be found in Chapter 6 from M.
Wien's book on \ac{HEVC}~\cite{wien-15-hevc}.
Depending on the prediction mode that has been used, transformed
coefficients present different patterns, making low and high values to
appear at different block positions.
This heterogeneity can be harmful for the entropy coding and the
\ac{CABAC}, which is why different scanning patterns exist in \ac{HEVC}.
These scanning patterns, presented in the lower part of
figure~\ref{fig:mdcs} depend only on the \ac{IPM} used to compute the
residual.
The patterns are described for $4\times4$ blocks, and the same pattern is used
on higher block sizes, which are recursively split into 4 sub-blocks until
size $4\times4$ is reached.

The top-right part of figure~\ref{fig:mdcs} presents the average
\ac{HEVC} $4\times4$ residuals by scanning mode, together with their
representation in the transform domain via de \ac{DST}.
The average residual profiles have lower (dark) values near the
available borders, which increase with the distance from the
boundaries: residuals issued from horizontal and vertical \acp{IPM} only
have the left and upper borders available, respectively, whereas the
remaining \acp{IPM} tend to have both borders available.
It can also be observed that the scanning patterns match reasonably well
the transform coefficients in each case, sorting them in an increasing
order.

The next section contains a summary of the most important studies
regarding intra coding carried out during the conception of \ac{HEVC}.

\begin{figure}[tb]
	\centering
	\begin{minipage}{0.48\textwidth}
		\input{figures/pred-directions.tex}
	\end{minipage}
	\begin{minipage}{0.48\textwidth}
		\centering
		\small
		Average profile for residuals (prediction direction)
		\begin{tabular}[H]{ccc}
			\includegraphics[width=0.25\textwidth]{figures/resids-scan-diag.png}
			& 
			\includegraphics[width=0.25\textwidth]{figures/resids-scan-horz.png}
			&
			\includegraphics[width=0.25\textwidth]{figures/resids-scan-vert.png}
			\\
			\color{red}{diagonal} & \color{mygreen}{vertical} & \color{blue}{horizontal} \\
			& & \\
		\end{tabular}
		\\
		\small
		Average profile for coefficients (scanning mode)
		\begin{tabular}[H]{ccc}
			\includegraphics[width=0.25\textwidth]{figures/coeffs-scan-diag.png}
			& 
			\includegraphics[width=0.25\textwidth]{figures/coeffs-scan-horz.png}
			&
			\includegraphics[width=0.25\textwidth]{figures/coeffs-scan-vert.png}
			\\
			\color{red}{diagonal} & \color{mygreen}{horizontal} & \color{blue}{vertical} \\
		\end{tabular}
	\end{minipage}
	\subfloat[Diagonal scanning]{\input{figures/mdcs-diag.tex}}
	\subfloat[Horizontal scanning]{\input{figures/mdcs-horz.tex}}
	\subfloat[Vertical scanning]{\input{figures/mdcs-vert.tex}}
	\caption{\acs{HEVC} intra prediction modes related to their average
	residual signals and their appropriate scanning in the transform
	domain}
	\label{fig:mdcs}
\end{figure}

\section{The story behind the \acs{DST}}
\label{sec:the_story_behind_the_dst}
\index{DST}
\index{KTA}
\index{TMuC}

The way of generating the prediction residuals leads to a particular
kind of signals with properties that differ from those of natural
images.
As a result, the \ac{DCT} is no longer a good approximation of the
\ac{KLT}.
For this reason, many studies were carried out in order to find better
performing transform for these signals.

Over the \ac{HEVC} standardisation phase, various techniques for
improving the performance of the H.264/\acs{MPEG}-4 \acs{AVC} were
explored and designated as \ac{KTA}.
Amongst those techniques, in order to improve the coding performance of
intra prediction residuals, an adapted transform for each \ac{IPM} (at
that time nine, which evolved into 35 in \ac{HEVC}), was included in the
\ac{KTA} software.
The adapted transforms were \acp{KLT}, and the resulting technique was
called \ac{MDDT}.
It became a core component of the \ac{TMuC}~\cite{JCTVC-A204} because of
its performance improvements over the previous standard.

During the \ac{JCT-VC} meetings, many efforts were done to yield the
first implementation of the \ac{MDDT}, which was non-separable, more
lightweight.

One of the first attempts was to make the \acp{KLT}
separable~\cite{JCTVC-B024}.
A fast algorithm was derived for the $4\times4$ transform by analysing
the correlation matrix of the intra prediction residuals, which can be
modelled using tridiagonal
matrices~\cite{yueh-05-eigenvalues-tridiagonal}.
In order to further reduce the complexity, rotational transforms were
also considered in~\cite{JCTVC-C096}.
The main idea was to use the \ac{DCT} followed by a secondary transform
implemented in the form of Given's rotations to improve the coding
efficiency.

The \ac{DST} was theoretically proved to be the optimal transform, in
terms of \ac{KLT} approximation, of the intra prediction residuals
in~\cite{JCTVC-C108, JCTVC-D033}.
It was used together with the \ac{DCT} as combinations of horizontal and
vertical transforms, depending on the \ac{IPM}.
However, it was not adopted in the \ac{TMuC} until the design of a fast
algorithm of the \ac{DST}, which introduced almost no increase in the
decoding time with regards to the \ac{DCT}.
It was only then when it fully replaced the \ac{MDDT}~\cite{JCTVC-D048,
JCTVC-E125, JCTVC-F283, JCTVC-G108}.
Finally, after many \acp{CE}, cross-checks between companies and
combinations of \ac{DST}, \ac{DCT} on different block sizes and luma and
chroma channels, the whole system was simplified by using the \ac{DST}
for all $4\times4$ luma intra prediction residuals, and the \ac{DCT} for
the rest of block sizes, due to the lack of fast algorithms and limited
gains, in both luma and chroma~\cite{JCTVC-J0021}.

In the following section, the \ac{MDDT} will be re-implemented using
both transforms designs from \S\ref{sec:the_karhunen_loeve_transform}
(\ac{KLT}) and \S\ref{sec:the_rate_distortion_optimised_transform}
(\ac{RDOT}), in both separable and non-separable fashions.

\section{The mode dependent directional transforms}
\label{sec:the_mode_dependent_directional_transforms}

Explain the VCIP publication~\cite{arrufat-14-mddt-rdot}
\subsection{Encoding and decoding schemes for the \ac{MDDT}}
\label{sub:encoding_and_decoding_schemes_for_the_mddt}

\begin{figure}[tp]
	\centering
	\input{./figures/mddt_enc.tex}
	\caption{Encoding scheme for the \ac{MDDT}}
	\label{fig:enc_mddt}
\end{figure}

\begin{figure}[tp]
	\centering
	\input{./figures/mddt_dec.tex}
	\caption{Decoding scheme for the \ac{MDDT}}
	\label{fig:dec_mddt}
\end{figure}

\subsection{Separable implementations}
\label{sub:separable_implementations}

The methods for transform design and learning presented in
Chapter~\ref{cha:transform_coding} regarding the \ac{KLT} and the
\ac{RDOT} are non-separable.
This means that the input block is linearised and then transformed in
one step.
In order to design and learn separable transforms, the methods have to
be adapted.
In the case of the \ac{KLT} is straightforward to see that one can learn
an horizontal \ac{KLT} to transform the rows of the signal and a
vertical \ac{KLT} for the columns.
However, the \ac{RDOT} algorithm needs further tunning in order to
obtain separable transforms.
A possible way of learning a separable \ac{RDOT} was also proposed by
Sezer~\cite{sezer-11-phd} and validated by independent
reseaches~\cite{sole-09-sparsity-optimisation-separable-transforms}.
The proposed method consists in updating each one of the horizontal and
vertical transforms separately.

\subsubsection{\ac{KLT}-based \ac{MDDT}}
\label{ssub:sep_klt_based_mddt}
\subsubsection{\ac{RDOT}-based \ac{MDDT}}
\label{ssub:sep_rdot_based_mddt}

\subsection{Non-separable implementations}
\label{sub:non_separable_implementations}

\subsubsection{\ac{KLT}-based \ac{MDDT}}
\label{ssub:nsep_klt_based_mddt}
\subsubsection{\ac{RDOT}-based \ac{MDDT}}
\label{ssub:nsep_rdot_based_mddt}

\section{Conclusions}
\label{sec:conclusions}

\part{Contributions}
\label{prt:contributions}

\chapter{The mode-dependent transform competition}
\label{cha:the_mode_dependent_transform_competition}
\chaptertoc

\vspace{0.5cm}
Maybe explain the VCIP

\begin{itemize}
	\item introduce transform competition with transform
		skip~\cite{JCTVC-F077, JCTVC-H0208}
	\item explain VCIP 2014~\cite{arrufat-14-transform-competition-rdot}
	\item explain ICIP 2015~\cite{arrufat-15-mdtc}
\end{itemize}

\chapter{Realistic system}
\label{cha:realistic_system}
\chaptertoc

\section{Motivation}
\label{sec:motivation}

This chapter will take a look at different approaches to simplify the
system presented in
Chapter~\ref{cha:the_mode_dependent_transform_competition} while trying
to degrade its performances as least as possible.

\subsection{Main drawbacks}
\label{sub:main_drawbacks}

\begin{itemize}
	\item Testing and learning on almost the same sequences
	\item Encoding time
	\item Decoding time
	\item Storage requirements
\end{itemize}

\subsection{Proposals}
\label{sub:proposals}

\begin{itemize}
	\item Usage of separable transforms
	\item Making use of symmetries in prediction modes
	\item Non-homogeneous transform repartition amongst prediction modes
\end{itemize}

\bookmarksetup{startatroot}% to remove Bibliography from the last part
\addtocontents{toc}{\bigskip}% add a separation to the ToC
\backmatter

\bibliographystyle{abbrv} % numbers
%\bibliographystyle{apalike} % Surname et al. 2014
%\bibliographystyle{alpha} % ABC14
\bibliography{refs}

\chapter*{List of Acronyms}
\label{cha:glossary}
\addcontentsline{toc}{chapter}{List of Acronyms}
\begin{acronym}[JCT-VC] % the option corresponds to the longest acronym
	\acro{AR}{autoregressive}
	\acro{AVC}{Advanced Video Coding}
	\acro{BD}{Bj{\o}ntegaard Delta}
	\acro{CABAC}{Context Adaptive Binary Arithmetic Coding}
	\acro{CE}{core experiment}
	\acro{DCT}{discrete cosine transform}
	\acro{DPCM}{differential pulse-code modulation}
	\acro{DST}{discrete sine transform}
	\acro{GGD}{generalised Gaussian distribution}
	\acro{HD}{High Definition}
	\acro{HEVC}{High Efficiency Video Coding}
	\acro{HVS}{Human Visual System}
	\acro{H}{entropy}
	\acro{IPM}{intra prediction mode}
	\acro{IP}{Internet Protocol}
	\acro{ITU-T}{\ac{ITU} Telecommunication Standardisation Sector}
	\acro{ITU}{International Telecommunication Union}
	\acro{JCT-VC}{Joint Collaborative Team on Video Coding}
	\acro{KLT}{Karhunen-Lo√®ve transform}
	\acro{KTA}{key technical areas}
	\acro{MDDT}{mode dependent directional transform}
	\acro{MPEG}{Moving Picture Experts Group}
	\acro{MSE}{mean squared error}
	\acro{PDF}{probability density function}
	\acro{PSNR}{peak signal-to-noise ratio}
	\acro{QP}{quantisation parameter}
	\acro{RDOT}{rate-distortion optimised transform}
	\acro{RDO}{rate-distortion optimisation}
	\acro{RGB}{red, green and blue}
	\acro{SOT}{sparse orthogonal transform}
	\acro{TMuC}{Test Model under Consideration}
	\acro{VCEG}{Video Coding Experts Group}
	\acro{VCIP}{Visual Communications and Image Processing}
\end{acronym}
\thispagestyle{empty}

\label{cha:index}
\printindex
\addcontentsline{toc}{chapter}{Index}
\thispagestyle{empty}

\end{document}
